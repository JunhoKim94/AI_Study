{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow as tf\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNN():\n",
    "    def __init__(self, etha, nodes, inputs, outputs):\n",
    "        self.etha = etha\n",
    "        self.hidden_nodes = nodes\n",
    "        self.input = np.array(inputs)\n",
    "        self.output = np.array(outputs)\n",
    "        self.NN_structure()\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        #return 1/(np.exp(-x)+1) -->소수점때문에 overflow 현상 일어나서 scipy 모듈로 대체\n",
    "        return expit(x)\n",
    "    \n",
    "    def sigmoid_prime(self,x):\n",
    "        return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "    \n",
    "    def NN_structure(self):\n",
    "        \n",
    "        bias = np.ones(shape=(len(self.input),1))\n",
    "        self.input = np.concatenate([self.input,bias],axis=1)\n",
    "        inputs_num = len(self.input[0])\n",
    "        outputs_num = len(self.output[0])\n",
    "        \n",
    "        #weight\n",
    "        self.w1 = np.random.rand(inputs_num,self.hidden_nodes)\n",
    "        self.w2 = np.random.rand(self.hidden_nodes+1,outputs_num)\n",
    "        \n",
    "        #Problem 3 weight\n",
    "        #self.w1 = np.array([[-0.089,0.098],[0.028,-0.07],[0.092,-0.01]])\n",
    "        #self.w2 = np.array([[0.056],[0.067],[0.016]])\n",
    "        \n",
    "    def run(self, iteration, verbose=False, Error_graph = False):\n",
    "        t= time.time()\n",
    "        y =[]\n",
    "        for j in range(1,iteration+1):\n",
    "            sum1 = 0\n",
    "            sum2 = 0\n",
    "            sum_Error = 0\n",
    "            for i in range(len(self.input)):\n",
    "                \n",
    "                #calculation until hidden node\n",
    "                net = np.matmul(self.input[i],self.w1)\n",
    "                h = self.sigmoid(net)\n",
    "                #add bias to hidden node\n",
    "                h = np.concatenate([h,np.ones(1).T])\n",
    "                \n",
    "                #calculation until output\n",
    "                o_net = np.matmul(h,self.w2)\n",
    "                o = self.sigmoid(o_net)\n",
    "\n",
    "                #Cost function\n",
    "                Error = 0.5*sum((o-self.output[i])*(o-self.output[i]))\n",
    "                \n",
    "                #delta weight\n",
    "                delta_w_2 = np.multiply((o-self.output[i]),self.sigmoid_prime(o))\n",
    "                delta_w_1 = np.matmul(self.w2,delta_w_2)\n",
    "                delta_w_1= self.sigmoid_prime(h[:-1])*delta_w_1[:-1]\n",
    "                delta_w_1 = self.etha*np.outer(self.input[i],delta_w_1)\n",
    "                delta_w_2 = self.etha*np.outer(h,delta_w_2)\n",
    "                #sum delta weights all cases\n",
    "                sum1 =sum1 + delta_w_1\n",
    "                sum2 =sum2 + delta_w_2\n",
    "                sum_Error += Error\n",
    "                \n",
    "                #print(net,h,o_net,o)\n",
    "                #print(delta_w_2,\"\\n\",delta_w_1)\n",
    "                \n",
    "            #update weight\n",
    "            self.w1 = self.w1 - sum1\n",
    "            self.w2 = self.w2 - sum2\n",
    "            \n",
    "            #current iteration, error, time\n",
    "            if (verbose == True):\n",
    "                if (j%5000) == 0 or (j == iteration):\n",
    "                    print(\"iteration: %d/%d, Error = %f, time: %f\"%(j,iteration,sum_Error,time.time()-t))\n",
    "            #Error - iteration graph\n",
    "            if Error_graph == True:\n",
    "                y.append(sum_Error)\n",
    "        if Error_graph == True:\n",
    "            plt.plot(np.linspace(1,iteration,iteration),y,'black')\n",
    "            plt.title(\"Error by iteration\",size=20)\n",
    "            plt.xlabel('Iteration',size=20)\n",
    "            plt.ylabel('Error',size=20)\n",
    "            plt.show()\n",
    "    def feed_forward(self,x):\n",
    "        bias = np.ones(shape=(1))\n",
    "        x = np.concatenate([x,bias])\n",
    "        net = np.matmul(x,self.w1)\n",
    "        h = self.sigmoid(net)\n",
    "        h = np.concatenate([h,np.ones(1).T])    \n",
    "        o_net = np.matmul(h,self.w2)\n",
    "        o = self.sigmoid(o_net)\n",
    "        return o\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5000/5000, Error = 0.500000, time: 1.306607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.08687985,  0.08647317],\n",
       "       [ 0.01736234, -0.05429326],\n",
       "       [ 0.09138746, -0.01105019]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "problem 3\n",
    "'''\n",
    "'''\n",
    "a = [[1,1],[1,0],[0,1],[0,0]]\n",
    "b= [[0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]]\n",
    "bp = BPNN(etha = 0.5 , nodes= 2 , inputs=a, outputs=b)\n",
    "bp.run(5000,verbose = True,Error_graph = False)\n",
    "bp.w1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5000/500000, Error = 0.042895, time: 3.337077\n",
      "iteration: 10000/500000, Error = 0.042882, time: 6.679143\n",
      "iteration: 15000/500000, Error = 0.042861, time: 9.987332\n",
      "iteration: 20000/500000, Error = 0.042869, time: 13.289505\n",
      "iteration: 25000/500000, Error = 0.042959, time: 16.617569\n",
      "iteration: 30000/500000, Error = 0.042946, time: 19.938726\n",
      "iteration: 35000/500000, Error = 0.042809, time: 23.249840\n",
      "iteration: 40000/500000, Error = 0.042899, time: 26.556998\n",
      "iteration: 45000/500000, Error = 0.042405, time: 29.886098\n",
      "iteration: 50000/500000, Error = 0.040032, time: 33.206218\n",
      "iteration: 55000/500000, Error = 0.041307, time: 36.509390\n",
      "iteration: 60000/500000, Error = 0.030768, time: 39.809567\n",
      "iteration: 65000/500000, Error = 0.015627, time: 43.096816\n",
      "iteration: 70000/500000, Error = 0.004691, time: 46.385982\n",
      "iteration: 75000/500000, Error = 0.004607, time: 49.682206\n",
      "iteration: 80000/500000, Error = 0.004442, time: 52.975403\n",
      "iteration: 85000/500000, Error = 0.003706, time: 56.280531\n",
      "iteration: 90000/500000, Error = 0.003041, time: 59.568783\n",
      "iteration: 95000/500000, Error = 0.002804, time: 62.872906\n",
      "iteration: 100000/500000, Error = 0.002912, time: 66.178067\n",
      "iteration: 105000/500000, Error = 0.003050, time: 69.499190\n",
      "iteration: 110000/500000, Error = 0.003076, time: 72.777464\n",
      "iteration: 115000/500000, Error = 0.003047, time: 76.058691\n",
      "iteration: 120000/500000, Error = 0.003000, time: 79.356875\n",
      "iteration: 125000/500000, Error = 0.002941, time: 82.678954\n",
      "iteration: 130000/500000, Error = 0.002886, time: 85.969157\n",
      "iteration: 135000/500000, Error = 0.002864, time: 89.268373\n",
      "iteration: 140000/500000, Error = 0.002924, time: 92.590496\n",
      "iteration: 145000/500000, Error = 0.003153, time: 95.887682\n",
      "iteration: 150000/500000, Error = 0.003685, time: 99.208761\n",
      "iteration: 155000/500000, Error = 0.004561, time: 102.521947\n",
      "iteration: 160000/500000, Error = 0.005373, time: 105.854992\n",
      "iteration: 165000/500000, Error = 0.005706, time: 109.191072\n",
      "iteration: 170000/500000, Error = 0.005638, time: 112.561100\n",
      "iteration: 175000/500000, Error = 0.005349, time: 115.898141\n",
      "iteration: 180000/500000, Error = 0.004966, time: 119.191337\n",
      "iteration: 185000/500000, Error = 0.004628, time: 122.488521\n",
      "iteration: 190000/500000, Error = 0.004557, time: 125.785741\n",
      "iteration: 195000/500000, Error = 0.004927, time: 129.077942\n",
      "iteration: 200000/500000, Error = 0.005540, time: 132.368141\n",
      "iteration: 205000/500000, Error = 0.006040, time: 135.679289\n",
      "iteration: 210000/500000, Error = 0.006325, time: 139.003407\n",
      "iteration: 215000/500000, Error = 0.006442, time: 142.294608\n",
      "iteration: 220000/500000, Error = 0.006447, time: 145.572839\n",
      "iteration: 225000/500000, Error = 0.006375, time: 148.902937\n",
      "iteration: 230000/500000, Error = 0.006246, time: 152.192105\n",
      "iteration: 235000/500000, Error = 0.006075, time: 155.538162\n",
      "iteration: 240000/500000, Error = 0.005874, time: 159.587333\n",
      "iteration: 245000/500000, Error = 0.005654, time: 163.745220\n",
      "iteration: 250000/500000, Error = 0.005428, time: 167.433360\n",
      "iteration: 255000/500000, Error = 0.005208, time: 170.740553\n",
      "iteration: 260000/500000, Error = 0.005002, time: 174.031758\n",
      "iteration: 265000/500000, Error = 0.004815, time: 177.587210\n",
      "iteration: 270000/500000, Error = 0.004650, time: 181.236456\n",
      "iteration: 275000/500000, Error = 0.004506, time: 184.896668\n",
      "iteration: 280000/500000, Error = 0.004382, time: 188.261676\n",
      "iteration: 285000/500000, Error = 0.004275, time: 191.568867\n",
      "iteration: 290000/500000, Error = 0.004181, time: 194.846109\n",
      "iteration: 295000/500000, Error = 0.004100, time: 198.186175\n",
      "iteration: 300000/500000, Error = 0.004027, time: 201.506264\n",
      "iteration: 305000/500000, Error = 0.003962, time: 204.880282\n",
      "iteration: 310000/500000, Error = 0.003904, time: 208.177467\n",
      "iteration: 315000/500000, Error = 0.003850, time: 211.461686\n",
      "iteration: 320000/500000, Error = 0.003800, time: 214.735928\n",
      "iteration: 325000/500000, Error = 0.003753, time: 218.032121\n",
      "iteration: 330000/500000, Error = 0.003709, time: 221.340237\n",
      "iteration: 335000/500000, Error = 0.003667, time: 224.662390\n",
      "iteration: 340000/500000, Error = 0.003627, time: 227.983516\n",
      "iteration: 345000/500000, Error = 0.003588, time: 231.273714\n",
      "iteration: 350000/500000, Error = 0.003550, time: 234.565917\n",
      "iteration: 355000/500000, Error = 0.003514, time: 237.933916\n",
      "iteration: 360000/500000, Error = 0.003478, time: 241.240034\n",
      "iteration: 365000/500000, Error = 0.003443, time: 244.560196\n",
      "iteration: 370000/500000, Error = 0.003409, time: 247.892283\n",
      "iteration: 375000/500000, Error = 0.003375, time: 251.185479\n",
      "iteration: 380000/500000, Error = 0.003342, time: 254.492637\n",
      "iteration: 385000/500000, Error = 0.003309, time: 257.911459\n",
      "iteration: 390000/500000, Error = 0.003277, time: 261.283448\n",
      "iteration: 395000/500000, Error = 0.003245, time: 264.645494\n",
      "iteration: 400000/500000, Error = 0.003214, time: 267.956641\n",
      "iteration: 405000/500000, Error = 0.003182, time: 271.279761\n",
      "iteration: 410000/500000, Error = 0.003152, time: 274.648712\n",
      "iteration: 415000/500000, Error = 0.003121, time: 277.952924\n",
      "iteration: 420000/500000, Error = 0.003091, time: 281.312936\n",
      "iteration: 425000/500000, Error = 0.003061, time: 284.605130\n",
      "iteration: 430000/500000, Error = 0.003032, time: 288.072825\n",
      "iteration: 435000/500000, Error = 0.003002, time: 291.843743\n",
      "iteration: 440000/500000, Error = 0.002973, time: 295.794271\n",
      "iteration: 445000/500000, Error = 0.002945, time: 299.909661\n",
      "iteration: 450000/500000, Error = 0.002916, time: 303.600857\n",
      "iteration: 455000/500000, Error = 0.002888, time: 307.528263\n",
      "iteration: 460000/500000, Error = 0.002861, time: 311.217028\n",
      "iteration: 465000/500000, Error = 0.002833, time: 315.145079\n",
      "iteration: 470000/500000, Error = 0.002806, time: 318.705600\n",
      "iteration: 475000/500000, Error = 0.002780, time: 322.102482\n",
      "iteration: 480000/500000, Error = 0.002753, time: 325.772668\n",
      "iteration: 485000/500000, Error = 0.002727, time: 329.228463\n",
      "iteration: 490000/500000, Error = 0.002701, time: 332.706131\n",
      "iteration: 495000/500000, Error = 0.002676, time: 336.190815\n",
      "iteration: 500000/500000, Error = 0.002651, time: 339.646576\n",
      "[[  4.7792656   -0.43725612 -38.57776414  11.92161106]\n",
      " [ -7.11055518  -2.59820505   7.01664077  -0.73912892]]\n",
      "[[-29.97162518]\n",
      " [ -0.3826814 ]\n",
      " [  3.5602362 ]\n",
      " [ 12.85790228]\n",
      " [-13.44758744]]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #make a target & input\n",
    "    x = np.arange(0,1.05,0.1).reshape(11,1)\n",
    "    target = f(x)\n",
    "    #NN create\n",
    "    quadratic = BPNN(0.7, 4, x, target)\n",
    "    \n",
    "    #NN run\n",
    "    quadratic.run(500000, verbose =True, Error_graph = True)\n",
    "    \n",
    "    #x for graph\n",
    "    a = np.linspace(0,1,100)\n",
    "    x = []\n",
    "    for i in a:\n",
    "        x.append(quadratic.feed_forward([i])[0])\n",
    "    #Graph \n",
    "    figure = plt.figure()\n",
    "    plt.plot(a,x,'r')\n",
    "    plt.plot(np.linspace(0,1,11),target,'b')\n",
    "    plt.title(\"Result\",size=20)\n",
    "    plt.legend(['train','target'],loc=2,prop={'size': 20})\n",
    "    plt.xlabel('Input',size=20)\n",
    "    plt.ylabel('Output',size=20)\n",
    "    plt.show()\n",
    "    #Print final weight\n",
    "    print(quadratic.w1)\n",
    "    print(quadratic.w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    a = np.linspace(0,1,100)\n",
    "    x = []\n",
    "    for i in a:\n",
    "        x.append(quadratic.feed_forward([i])[0])\n",
    "    #Graph \n",
    "    figure = plt.figure()\n",
    "    plt.plot(a,x,'r')\n",
    "    plt.plot(np.linspace(0,1,11),target,'b')\n",
    "    plt.title(\"Result\",size=20)\n",
    "    plt.legend(['train','target'],loc=2,prop={'size': 20})\n",
    "    plt.xlabel('Input',size=20)\n",
    "    plt.ylabel('Output',size=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
